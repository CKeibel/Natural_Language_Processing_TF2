{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character_RNN_Shakespeare.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6YbAt7uoqhL"
      },
      "source": [
        "# Buchstabenvorhersage zum Erstellen von Shakespeare Texten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmoMaoyNoQ2n",
        "outputId": "6079a1b8-7c35-4e48-ff79-6012394b7c9b"
      },
      "source": [
        "# get data\r\n",
        "!wget \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-23 10:42:44--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-01-23 10:42:44 (48.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cpWj_ymo_8I"
      },
      "source": [
        "# read data\r\n",
        "PATH = \"input.txt\"\r\n",
        "\r\n",
        "with open(PATH) as f:\r\n",
        "    text = f.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgtO0IuAqmWo"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "# map words to int\r\n",
        "tokenizer = Tokenizer(char_level=True) # characterwise\r\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4IY6m23r2tj"
      },
      "source": [
        "### Testing/playing with Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx7hR5ATrbaN",
        "outputId": "4b3c6086-e3c5-4e26-cb9b-54d543094513"
      },
      "source": [
        "# map \"Hallo Welt!\" to sequence\r\n",
        "hallo_welt = tokenizer.texts_to_sequences([\"Hallo Welt!\"])\r\n",
        "hallo_welt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 5, 12, 12, 4, 1, 17, 2, 12, 3, 31]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOCYYXu1sEXj",
        "outputId": "8c600e5a-b93c-4d47-fcea-f9eb234619f5"
      },
      "source": [
        "# map sequnce back to text\r\n",
        "hallo_welt = tokenizer.sequences_to_texts(hallo_welt)\r\n",
        "hallo_welt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h a l l o   w e l t !']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5roMmbpzsajN",
        "outputId": "1b0c9840-10ae-4d06-991d-756fabe1748f"
      },
      "source": [
        "# different charakters in tokenizer\r\n",
        "max_id = len(tokenizer.word_index)\r\n",
        "max_id"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nua1E4Bqssb0",
        "outputId": "d4c7b87b-3707-4064-c78c-af3274fce840"
      },
      "source": [
        "# total count of characters\r\n",
        "dataset_size = tokenizer.document_count\r\n",
        "dataset_size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Sv6453tPRJ"
      },
      "source": [
        "### Preprocessing the Shakespeare Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwzXO67HtERc",
        "outputId": "1c756fcd-4c7a-48aa-be81-50b8f279ae75"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# map text to sequence\r\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([text])) -1 # -1 to get indices from 0 to N\r\n",
        "encoded, len(encoded)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([19,  5,  8, ..., 20, 26, 10]), 1115394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6GLjVnldv8O5",
        "outputId": "c7cbcc64-b548-4e6c-b9da-fec9bef0bb8a"
      },
      "source": [
        "# create dataset\r\n",
        "train_size = int(dataset_size * 0.9) # 90% training data\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size]) # 0 to train_size\r\n",
        "\"\"\" dataset is one long sequence now \"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' dataset is one long sequence now '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mnbiIZGYx7T7",
        "outputId": "6397359d-ea8e-4743-a189-18f710c07eaf"
      },
      "source": [
        "# cut the dataset into small sequences\r\n",
        "n_steps = 100\r\n",
        "window_length = n_steps + 1\r\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\r\n",
        "\"\"\" dataset is a nested dataset now \"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' dataset is a nested dataset now '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-QQYnPt0LzC"
      },
      "source": [
        "# flatten the nested dataset to a normal dataset\r\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikdQfKEx08gm"
      },
      "source": [
        "# shuffle dataset\r\n",
        "batch_size = 32\r\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\r\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B11DlZ4d15k1"
      },
      "source": [
        "# create one-hots, because of the few characters (39)\r\n",
        "dataset = dataset.map(\r\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\r\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOSXLORP2b0E"
      },
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AxzrT_A24nf"
      },
      "source": [
        "### Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h09_XDVY27Ni",
        "outputId": "6d539dc4-b84a-4656-8661-291209fed3de"
      },
      "source": [
        "from tensorflow.keras.layers import GRU\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import TimeDistributed\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(GRU(units=128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2))\r\n",
        "model.add(GRU(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\r\n",
        "model.add(TimeDistributed(Dense(units=max_id, activation=\"softmax\")))\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    loss=\"sparse_categorical_crossentropy\",\r\n",
        "    optimizer=\"adam\"\r\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki3nxCO44uRJ",
        "outputId": "f50bba7b-c669-40f4-b122-d86e90e32b4a"
      },
      "source": [
        "history = model.fit(dataset, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "    762/Unknown - 502s 652ms/step - loss: 2.5767"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}